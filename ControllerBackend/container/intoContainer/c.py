import os, subprocess, dataObjects, json, signal
#sys import to put temp dir relative to main.py
#can be removed when that's a fixed absolute path
import sys
from pycparser import c_parser, c_ast, parse_file

# Path for temp files.
PATH = os.path.join(os.path.dirname(os.path.abspath(sys.argv[0])), "temp")
# Keeps files created in temp folder if DEBUG = True
DEBUG = True

class C:
    """ Class for processing, compiling, running and evaluating C code.

    Attributes:
        solution (Solution):
            Solution object storing data from solution json and the corresponding exercise object
        result (Result):
            Result object storing evaluation data generated by this class.
    """
    def __del__(self):
        """ Destructor deletes files in temp folder after execution 
        """
        if os.path.isdir(PATH) and not DEBUG:
            for f in os.scandir(PATH):
                os.remove(f.path)
            print("temp folder cleared")

    def __init__(self, solution : dataObjects.Solution, config : dict = None, id : int = None):
        """ Constructor

        Args:
            solution (Solution):
                The solution object storing data from solution json and exercise object
        """
        self.result = dataObjects.Result(dataObjects.readJson(solution.createJson()))
        self.solution = solution
        self.cfg = {} if config is None else config
        self._lang = self.solution.exercise.lang
        self._fileext = "c" if self._lang == "C" else "cpp"
        if id is not None:
            self.result.setId(id)

    def processData(self):
        """ Processes code, generates files and runs them to get a result.
        """
        # Creates temp dir if it does not exist
        if not os.path.exists(PATH):
            os.makedirs(PATH)
            print("created temp folder")

        # Prepare code by replacing placeholder code with solutions code
        self.replaceCodeWithSolution()

        maxState = self.getMaxState()
        # Step 1: Merge source code
        exitcode, self.fileInfo = self.merge()
        #print(f"fileInfo:\n{json.dumps(self.fileInfo, indent = 2)}")
        # Step 2: Compile files containing source code
        if exitcode == 0 and 1 <= maxState:
            try:
                exitcode = self.compile()
            except Exception as e:
                print("UNEXPECTED ERROR IN COMPILING", self.result.computation["technicalInfo"]["ID"])
                self.result.computation["userInfo"]["summary"] = "UNEXPECTED ERROR IN COMPILING"
                self.result.computation["userInfo"]["elements"].append(f"{type(e).__name__}: {e}")
                exitcode = 1
        # Step 3 (Only C): Check if student's solution contains illegal calls
        if exitcode == 0 and 2 <= maxState and self._lang == "C":
            try:
                exitcode = self.check()
            except Exception as e:
                print("UNEXPECTED ERROR IN CHECKING", self.result.computation["technicalInfo"]["ID"])
                self.result.computation["userInfo"]["summary"] = "UNEXPECTED ERROR IN CHECKING"
                self.result.computation["userInfo"]["elements"].append(f"{type(e).__name__}: {e}")
                exitcode = 1
        # Step 4: Link compiled files and libraries
        if exitcode == 0 and 3 <= maxState:
            try:
                exitcode = self.link()
            except Exception as e:
                print("UNEXPECTED ERROR IN LINKING", self.result.computation["technicalInfo"]["ID"])
                self.result.computation["userInfo"]["summary"] = "UNEXPECTED ERROR IN LINKING"
                self.result.computation["userInfo"]["elements"].append(f"{type(e).__name__}: {e}")
                exitcode = 1
        # Step 5: Run exectutable files
        if exitcode == 0 and 4 <= maxState:
            try:
                self.run()
            except Exception as e:
                print("UNEXPECTED ERROR IN RUNNING", self.result.computation["technicalInfo"]["ID"])
                self.result.computation["userInfo"]["summary"] = "UNEXPECTED ERROR IN RUNNING"
                self.result.computation["userInfo"]["elements"].append(f"{type(e).__name__}: {e}")
                exitcode = 1

        # Calculating computation time in result object
        self.result.computation["technicalInfo"]["exitCode"] = exitcode
        self.result.calculateComputationTime()

    def getMaxState(self) -> int:
        """ Retrieves max state of data processing 

        Returns:
            An integer representing the max state 
        """
        s = self.solution.exercise.config.get("stopAfterPhase")
        return 4 if s is None or s == "running" else \
            3 if s == "linking" else \
            2 if s == "checking" else \
            1 if s == "compiling" else 0
    
    def replaceCodeWithSolution(self):
        """ Modifying exercise code by replacing placeholder code with student solution
        """
        for sEl in self.solution.exerciseModifications["elements"]:
            for eEl in self.solution.exercise.elements:
                if eEl["identifier"] == sEl["identifier"] and eEl.get("modifiable") == True:
                    eEl["value"] = sEl["value"]
                    break

    def mergeError(self):
        self.result.computation["userInfo"]["summary"] = "[ERROR]"
        self.result.computation["userInfo"]["elements"].append({
            "severity": "error",
            "type": "chain",
            "message": "Merging failed! Empty merging array"
        })
        return 1, {}

    def merge(self):
        """ Merges all code snippets given by exercise json in config.merging

        Returns:
            A dict containing one dict per merged source file.
                - key: filename (without extension)
                - value: dict
            The structure of each of these dicts describing source files:
                - key: identifier of code snippet
                - value: dict containing following (keys: values):
                    - "visible": Bool indicating if section is visible for student
                    - "start": Integer indicating Start of Section (line number)
                    - "stop": Integer indicating End of Section (line number)
        """
        merge = self.solution.exercise.config["merging"]

        l = len(merge)

        if l == 0:
            return self.mergeError()
        if isinstance(merge, list) and isinstance(merge[0], dict) and l != 1:
            return self.mergeMultipleFiles()
        else:
            return self.mergeSingleFile()


    def mergeSingleFile(self) -> dict:
        """ Merges a single file.

        Returns:
            A dict as specified as in "merge".
            The filename is always "temp"
        """
        fname = f"temp.{self._fileext}"
        r = {fname : {}}
        code = ""
        loc = 0 # complete LoC Count
        vLoc = 0 # visible LoC Count

        if isinstance(self.solution.exercise.config["merging"], list):
            sourceElements = self.solution.exercise.config["merging"]
        else:
            sourceElements = self.solution.exercise.config["merging"]["sources"]
            if len(sourceElements) == 0:
                return self.mergeError()

        for s in sourceElements:
            for e in self.solution.exercise.elements:
                if s == e["identifier"]:
                    r[fname][s] = {}
                    if e.get("visible") is not None:
                        r[fname][s]["visible"] = e["visible"]
                    r[fname][s]["start"] = (loc + 1)
                    code += e["value"] or "\n"
                    if not code.endswith("\n"):
                        code += "\n"
                    cnt = (e["value"] or "\n").count("\n")
                    loc += cnt
                    r[fname][s]["stop"] = loc if cnt != 0 else (loc + 1)

                    if e.get("visible"):
                        r[fname][s]["vStart"] = (vLoc + 1)
                        vLoc += cnt
                        r[fname][s]["vStop"] = vLoc if cnt != 0 else (vLoc + 1)
                    break

        fpath = os.path.join(PATH, f"{fname}")

        with open(fpath, "w+") as f:
            f.write(code)
        os.chmod(fpath, 0o666)
        return 0, r

    def getFileName(self, mergeDict, cnt):
        mName = mergeDict.get("mergeID")
        if mName:
            fname = mName
        else:
            fname = f"temp{cnt}"
        
        return f"{fname}.{self._fileext}", cnt + 1

    def mergeMultipleFiles(self) -> dict:
        """ Merges multiple files.

        Returns:
            A dict as specified as in "merge".
        """
        i = 1 # used if neither mergeID nor mapping is given
        r = {}
        for m in self.solution.exercise.config["merging"]:
            fname, i = self.getFileName(m, i)
            
            loc = 0
            vLoc = 0
            r[fname] = {}
            code = ""
            for s in m["sources"]:
                for e in self.solution.exercise.elements:
                    if s == e["identifier"]:
                        r[fname][s] = {}
                        if e.get("visible") is not None:
                            r[fname][s]["visible"] = e["visible"]
                        r[fname][s]["start"] = (loc + 1)
                        code += e["value"]
                        if not code.endswith("\n"):
                            code += "\n"
                        cnt = e["value"].count("\n")
                        loc += cnt
                        r[fname][s]["stop"] = loc if cnt != 0 else (loc + 1)
                        if e.get("visible"):
                            r[fname][s]["vStart"] = (vLoc + 1)
                            vLoc += cnt
                            r[fname][s]["vStop"] = vLoc if cnt != 0 else (vLoc + 1)
                        break
            loc += 1

            if self.solution.exercise.elementMap is not None:
                mapInfo = self.solution.exercise.elementMap.get(fname)
                if mapInfo:
                    mergedFname = mapInfo.split(os.sep)[-1]
                    fpath = fpath = os.path.join(PATH, mergedFname)
                else:
                    fpath = os.path.join(PATH, f"{fname}.{self._fileext}")
            else:
                fpath = os.path.join(PATH, f"{fname}.{self._fileext}")



            #fpath = os.path.join(PATH, f"{fname}.{self._fileext}")
            with open(fpath, "w+") as f:
                f.write(code)
            os.chmod(fpath, 0o666)
        return 0, r

    def getSnippetIdentifier(self, file, line):
        for i in self.fileInfo[file]:
            if line >= self.fileInfo[file][i]["start"] and line <= self.fileInfo[file][i]["stop"]:
                return i

    def getLoc(self, file, line, join=False):
        with open(file if not join else os.path.join(PATH, file), "r") as f:
            i = 0
            while i < line - 1:
                f.readline()
                i += 1
            return f.readline()

    def compile(self):
        """ Compiles all merged source files.
        """
        # changes current working directory for easier compiling
        cwd = os.getcwd()
        os.chdir(PATH)

        # array containing all filenames of files to be compiled. If that information is not 
        # given in exercise's config, all merged files will be compiled
        files = self.solution.exercise.config["compiling"].get("sources")
        files = files if files is not None else self.fileInfo

        # compiling command as specified as in exercise
        com = self.solution.exercise.getCompilingCommand().split(" ")
        com.append("-c")
        # filenames of files to be compiled, each with the correct file extension
        com.append(' '.join([f'{s}.{self._fileext}' for s in files if '.h' not in s]))
        # flag for easier error handling. Requires GCC 9.4
        com.append("-fdiagnostics-format=json")

        self.result.computation["technicalInfo"]["compileCommand"] = " ".join(com)
        #proc = subprocess.run(com.split(" "), stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        proc = subprocess.run(com, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        #print(f"Proc Output (Len {len(proc.stdout)}):\n{proc.stdout.decode('utf-8')}\n---")

        try:
            parsed = json.loads(proc.stdout.decode("utf-8"))
        
        except json.decoder.JSONDecodeError:
            txt = proc.stdout.decode("utf-8")
            if txt[0] == "[":
                sliceIdx = txt.rfind("]")
            else:
                sliceIdx = txt.rfind("}")
            sliced = txt[:sliceIdx + 1]
            try:
                parsed = json.loads(sliced)
            except json.decoder.JSONDecodeError:
                parsed = sliced

        if len(parsed) > 0:
            if isinstance(parsed, dict):
                maxState = "info"
                elements = []
                for p in parsed:
                    # updating maxState if neccessary
                    if p["kind"] == "warning" and maxState == "info":
                        maxState = "warning"
                    elif p["kind"] == "error" and maxState != "error":
                        maxState = "error"

                    # file and line of error
                    file = p["locations"][0]["caret"]["file"].split(".")[0]
                    line = p["locations"][0]["caret"]["line"]

                    # calculating the line 
                    snippet = self.getSnippetIdentifier(file, line)

                    # dict specifying the current error/warning/info and source
                    e = {
                        "severity" : p["kind"],
                        "type" : "compiler",
                        "message" : p["message"],
                        "source" : {
                            "elementID" : snippet,
                            "extract" : self.getLoc(f"{file}.{self._fileext}", line, join=True),
                            "begin" : self.fileInfo[file][snippet]["start"],
                            "end" : self.fileInfo[file][snippet]["stop"],
                            "line" : line - self.fileInfo[file][snippet]["start"],
                            "col" : p["locations"][0]["caret"]["column"]
                        }
                    }
                    elements.append(e)
                    
                self.result.computation["userInfo"]["summary"] = f"[{maxState.upper()}]"
                self.result.computation["userInfo"]["elements"] += elements
            elif isinstance(parsed, str):
                maxState = "error" if "error" in parsed else "warning" if "warning" in parsed else "info"
                self.result.computation["userInfo"]["summary"] = f"[{maxState.upper()}] - could not parse output"
                self.result.computation["userInfo"]["elements"].append({
                    "severity": maxState,
                    "type": "compiler",
                    "message": "Could not parse output"
                })
            else: # list
                self.result.computation["userInfo"]["elements"] += parsed
            
        # adds compiling output to "elements" in result object
        data = {
            "MIMEtype":"text/plain",
            "identifier":f"{self.result.id} Compiling",
            "value" : parsed
        }
        self.result.elements.append(data)
        os.chdir(cwd)
        return proc.returncode

    def check(self):
        """ Checks all merged source files.
        Checking after compiling to reduce effort. It's unnecessary to check if compiling fails.
        """
        checkConfig = self.solution.exercise.config.get("checking")
        if checkConfig is None:
            return 0

        returncode = 0
        forbidden = checkConfig["forbiddenCalls"].split(" ")
        checker = Checker(self.fileInfo)
        for a in checker.asts:
            checker.getFunctions(checker.asts[a])

        #print(json.dumps(checker.visitor.data, indent=4))
        elements = []

        for file in checker.visitor.data:
            f = file.split(os.sep)[-1][:-(len(self._fileext) + 1)]
            for func in checker.visitor.data[file]:
                for i in checker.visitor.data[file][func]:
                    cur = checker.visitor.data[file][func][i]
                    id = self.getSnippetIdentifier(f, cur["Line"])
                    if id in checkConfig["sources"] and cur["FuncCall"] in forbidden:

                        line = cur["Line"] - self.fileInfo[f][id]["start"]

                        e =  {
                            "severity": "error",
                            "type": "callcheck",
                            "message": f"[C function filtering] Function call not allowed:\n\'"
                                f"{cur['FuncCall']}\';original source: f'{id}', line "
                                f"(corrected): {line}, " \
                                f"col: {cur['Column']}\nForbidden calls:\nsystem.\n",
                        
                            "source": {
                                "elementID": id,
                                "extract": self.getLoc(file, line),
                                "begin": self.fileInfo[f][id]["start"],
                                "end": self.fileInfo[f][id]["stop"],
                                "line": line,
                                "col": cur["Column"]
                            }
                        }
                        elements.append(e)

                        if returncode == 0:
                            returncode = 1
                        
        if len(elements) != 0:
            if "elements" not in self.result.computation["userInfo"]:
                self.result.computation["userInfo"]["elements"] = elements
            else:
                self.result.computation["userInfo"]["elements"] += elements
            
            if "summary" not in self.result.computation["userInfo"]:
                self.result.computation["userInfo"]["summary"] = "[ERROR]"
            elif "ERROR" not in self.result.computation["userInfo"]["summary"]:
                self.result.computation["userInfo"]["summary"] = "[ERROR]"

        data = {
            "MIMEtype":"text/plain",
            "identifier":f"{self.result.id} Checking",
            "value" : elements
        }
        self.result.elements.append(data)
        return returncode

    def link(self):
        """ Links compiled files and libraries.
        """
        com = ["gcc" if self._lang == "C" else "g++", "-o", f"{os.path.join(PATH, 'out')}"]
        com.append(f"{' '.join([os.path.join(PATH, f'{s}.o') for s in self.fileInfo])}")

        flags = self.solution.exercise.config["linking"].get("flags")
        if flags:
            com.append(flags)

        self.result.computation["technicalInfo"]["linkCommand"] = " ".join(com)
        proc = subprocess.run(com, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
        data = {
            "MIMEtype":"text/plain",
            "identifier":f"{self.result.id} Linking",
            "value" : proc.stdout.decode("utf-8")
        }
        self.result.elements.append(data)
        return proc.returncode
    
    def run(self):
        """ Makes file executable and runs it.
        """
        os.chmod(os.path.join(PATH, "out"), 0o700)
        com = [f"{os.path.join(PATH, 'out')}"]
        cmdLineArgs = self.solution.exercise.config["running"].get("commandLineArguments")
        if cmdLineArgs is not None:
            com.append(f" {cmdLineArgs}")

        # Time Limit of running process
        timelimit = self.solution.exercise.config["running"].get("timelimitInSeconds")
        cfglimit = self.cfg.get("timelimitInSeconds")
        if not timelimit:
            timelimit = cfglimit # is now either None or int
        elif cfglimit:
                timelimit = min(timelimit, cfglimit)

        self.result.computation["technicalInfo"]["runCommand"] = "".join(com)

        proc = subprocess.Popen(com, stdout=subprocess.PIPE, stderr=subprocess.PIPE,
            preexec_fn=os.setsid, shell=False)
        try:
            stdout, stderr = proc.communicate(timeout=timelimit)
            text = ""
        except subprocess.TimeoutExpired as e:
            os.killpg(os.getpgid(proc.pid), signal.SIGKILL)
            stdout, stderr, text = "", "", f"Runtime failed! Timeout after {e.timeout} seconds"
            self.result.computation["userInfo"]["summary"] = "Runtime failed! Exit code: 1"

        data = [{
            "MIMEtype":"text/plain",
            "identifier":f"{self.result.id} Running",
            "value" : text
        },
        {
            "MIMEtype":"text/plain",
            "identifier":f"{self.result.id} Running stdout",
            "value" : stdout#.decode("utf-8")
        },
        {
            "MIMEtype":"text/plain",
            "identifier":f"{self.result.id} Running stderr",
            "value" : stderr#.decode("utf-8")
        }]
        for d in data:
            self.result.elements.append(d)
        return proc.returncode

class Checker:
    """ Class for generating Abstract Syntax Trees (AST) of source files
        and retrieving informations about function calls.
    
    Attributes:
        asts (dict):
            A dict containing one entry for each merged source file
                - key: filename (without extension)
                - value: AST of source file
    """

    def __init__(self, files: dict):
        """ Constructor

        Args:
            files (dict):
                A dict generated by the "merge" function in class "C"
        """
        self._files = files
        self.asts = self.getAsts()
        self.visitor = self.Visitor()

    class Visitor(c_ast.NodeVisitor):
        """ Internal Class for visiting nodes in an AST.
        """
        def __init__(self):
            self.data = {}
        
        def visit_FuncDef(self, node):
            """ Finds and prints all found function calls in a function
            """
            if node.decl.coord.file not in self.data:
                self.data[node.decl.coord.file] = {}
            self.data[node.decl.coord.file][node.decl.name] = {}
            #print(f"File: {node.decl.coord.file}")
            i = 0
            for n in node.body.block_items:
                if isinstance(n, c_ast.FuncCall):
                    self.data[node.decl.coord.file][node.decl.name][str(i)] = {
                        "FuncCall" : n.name.name,
                        "Line" : n.coord.line,
                        "Column" : n.coord.column
                    }
                    i += 1

    def getAst(self, filename) -> c_ast.FileAST:
        """ Generates an AST from given source file

        Args:
            filename (str):
                The name of the source file to generate an AST for
        """
        fake_libc_include = os.path.join(os.path.dirname(os.path.abspath(sys.argv[0])), 
            'utils', 'fake_libc_include')
        return parse_file(filename, use_cpp=True, cpp_path="gcc",
            cpp_args=["-E", f"-I{fake_libc_include}"])

    def getAsts(self) -> dict:
        """ Generates one AST for each merged source file

        Returns:
            A dict containing one (key, value) pair for each source file.
                - key: filename (without extension)
                - value: AST for the corresponding file
        """
        asts = {}
        for f in self._files:
            asts[f] = self.getAst(os.path.join(PATH, f"{f}.c"))
        return asts
    
    def getFunctions(self, ast: c_ast.FileAST):
        """ Iterates over the given AST and visit nodes as specified as in Visitor class
        Args:
            ast:
                An AST representing a source file.
        """
        self.visitor.visit(ast)
